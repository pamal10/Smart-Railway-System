{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6088bae1-4720-442a-ad21-5574d0741600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\amal p\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.4.2)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\amal p\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\amal p\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.13.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\amal p\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.4.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\amal p\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (3.4.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0dfbdc2d-5023-4b51-8756-aaa0b4e328e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\amal p\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.16.1)\n",
      "Requirement already satisfied: tensorflow-intel==2.16.1 in c:\\users\\amal p\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow) (2.16.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\amal p\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\amal p\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\amal p\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\amal p\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\amal p\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in c:\\users\\amal p\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\amal p\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in c:\\users\\amal p\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\amal p\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\amal p\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (24.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\amal p\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\amal p\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\amal p\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (69.5.1)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\amal p\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\amal p\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\amal p\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\amal p\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\amal p\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.62.2)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in c:\\users\\amal p\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.16.2)\n",
      "Requirement already satisfied: keras>=3.0.0 in c:\\users\\amal p\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in c:\\users\\amal p\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\amal p\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.16.1->tensorflow) (0.43.0)\n",
      "Requirement already satisfied: rich in c:\\users\\amal p\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: namex in c:\\users\\amal p\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\amal p\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\amal p\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\amal p\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\amal p\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\amal p\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2023.7.22)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\amal p\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\amal p\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\amal p\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\amal p\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\amal p\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\amal p\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (2.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\amal p\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61334968-78c1-4b4d-ad2b-0e1137d11cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "from tracker import Tracker\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa150da7-b965-4629-af31-8437fe004775",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = \"D:/Project_data/Test_vid.mp4\"\n",
    "video_out_path = os.path.join('.', 'out.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d27a9e8-2d1c-4233-8840-a1f05e4a96ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "area1=[(312,388),(289,390),(474,469),(497,462)]\n",
    "\n",
    "area2=[(279,392),(250,397),(423,477),(454,469)]\n",
    "#area1=[(312,388),(497,390),(474,469),(497,462)]\n",
    "\n",
    "\n",
    "#area2=[(279,392),(454,450),(423,477),(454,469)]\n",
    "def RGB(event, x, y, flags, param):\n",
    "    if event == cv2.EVENT_MOUSEMOVE :  \n",
    "        colorsBGR = [x, y]\n",
    "        print(colorsBGR)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30af1217-d3e5-467f-9a30-0255cf3bfee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Amal P\\Desktop\\Python_Projects\\Project\\object-tracking-yolov8-deep-sort\\deep_sort\\tools\\generate_detections.py:79: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "\n",
      "0: 384x640 11 persons, 3 cars, 3 backpacks, 110.3ms\n",
      "Speed: 4.0ms preprocess, 110.3ms inference, 695.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Number of detections: 11\n",
      "---------------\n",
      "[]\n",
      "---------------\n",
      "Matches A\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "None\n",
      "Hi\n",
      "[]\n",
      "Number of tracks: 0\n",
      "\n",
      "0: 384x640 11 persons, 4 cars, 1 motorcycle, 3 backpacks, 84.1ms\n",
      "Speed: 1.8ms preprocess, 84.1ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Number of detections: 12\n",
      "---------------\n",
      "[]\n",
      "---------------\n",
      "Matches A\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "None\n",
      "Hi\n",
      "[]\n",
      "Number of tracks: 0\n",
      "\n",
      "0: 384x640 14 persons, 3 cars, 1 motorcycle, 4 backpacks, 90.4ms\n",
      "Speed: 10.1ms preprocess, 90.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Number of detections: 15\n",
      "---------------\n",
      "[]\n",
      "---------------\n",
      "Matches A\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "None\n",
      "Hi\n",
      "[]\n",
      "Number of tracks: 0\n",
      "\n",
      "0: 384x640 12 persons, 5 cars, 1 motorcycle, 4 backpacks, 91.8ms\n",
      "Speed: 4.6ms preprocess, 91.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Number of detections: 14\n",
      "---------------\n",
      "[]\n",
      "---------------\n",
      "Matches A\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "None\n",
      "Hi\n",
      "[]\n",
      "Number of tracks: 0\n",
      "\n",
      "0: 384x640 13 persons, 8 cars, 1 motorcycle, 4 backpacks, 1 handbag, 90.3ms\n",
      "Speed: 2.2ms preprocess, 90.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Number of detections: 14\n",
      "---------------\n",
      "[]\n",
      "---------------\n",
      "Matches A\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "None\n",
      "Hi\n",
      "[]\n",
      "Number of tracks: 0\n",
      "\n",
      "0: 384x640 12 persons, 6 cars, 1 motorcycle, 4 backpacks, 1 handbag, 86.1ms\n",
      "Speed: 2.7ms preprocess, 86.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Number of detections: 14\n",
      "---------------\n",
      "[]\n",
      "---------------\n",
      "Matches A\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "None\n",
      "Hi\n",
      "[]\n",
      "Number of tracks: 0\n",
      "\n",
      "0: 384x640 12 persons, 6 cars, 1 motorcycle, 3 backpacks, 92.6ms\n",
      "Speed: 2.0ms preprocess, 92.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Number of detections: 15\n",
      "---------------\n",
      "[]\n",
      "---------------\n",
      "Matches A\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "None\n",
      "Hi\n",
      "[]\n",
      "Number of tracks: 0\n",
      "\n",
      "0: 384x640 9 persons, 6 cars, 1 motorcycle, 4 backpacks, 1 handbag, 89.2ms\n",
      "Speed: 9.0ms preprocess, 89.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Number of detections: 15\n",
      "---------------\n",
      "[]\n",
      "---------------\n",
      "Matches A\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "None\n",
      "Hi\n",
      "[]\n",
      "Number of tracks: 0\n",
      "\n",
      "0: 384x640 11 persons, 6 cars, 1 motorcycle, 5 backpacks, 1 handbag, 95.0ms\n",
      "Speed: 2.5ms preprocess, 95.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Number of detections: 15\n",
      "---------------\n",
      "[]\n",
      "---------------\n",
      "Matches A\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "None\n",
      "Hi\n",
      "[]\n",
      "Number of tracks: 0\n",
      "\n",
      "0: 384x640 10 persons, 6 cars, 1 motorcycle, 4 backpacks, 1 handbag, 98.4ms\n",
      "Speed: 2.6ms preprocess, 98.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Number of detections: 17\n",
      "---------------\n",
      "[]\n",
      "---------------\n",
      "Matches A\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "None\n",
      "Hi\n",
      "[]\n",
      "Number of tracks: 0\n",
      "\n",
      "0: 384x640 10 persons, 6 cars, 3 backpacks, 1 handbag, 92.0ms\n",
      "Speed: 1.2ms preprocess, 92.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Number of detections: 17\n",
      "---------------\n",
      "[]\n",
      "---------------\n",
      "Matches A\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "None\n",
      "Hi\n",
      "[]\n",
      "Number of tracks: 0\n",
      "\n",
      "0: 384x640 12 persons, 6 cars, 3 backpacks, 1 handbag, 101.6ms\n",
      "Speed: 2.3ms preprocess, 101.6ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Number of detections: 16\n",
      "---------------\n",
      "[]\n",
      "---------------\n",
      "Matches A\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "None\n",
      "Hi\n",
      "[]\n",
      "Number of tracks: 0\n",
      "\n",
      "0: 384x640 11 persons, 6 cars, 3 backpacks, 1 handbag, 98.3ms\n",
      "Speed: 0.0ms preprocess, 98.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Number of detections: 15\n",
      "---------------\n",
      "[]\n",
      "---------------\n",
      "Matches A\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "None\n",
      "Hi\n",
      "[]\n",
      "Number of tracks: 0\n",
      "\n",
      "0: 384x640 12 persons, 7 cars, 3 backpacks, 1 handbag, 95.0ms\n",
      "Speed: 5.0ms preprocess, 95.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Number of detections: 15\n",
      "---------------\n",
      "[]\n",
      "---------------\n",
      "Matches A\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "None\n",
      "Hi\n",
      "[]\n",
      "Number of tracks: 0\n",
      "\n",
      "0: 384x640 11 persons, 7 cars, 3 backpacks, 97.3ms\n",
      "Speed: 2.0ms preprocess, 97.3ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Number of detections: 15\n",
      "---------------\n",
      "[]\n",
      "---------------\n",
      "Matches A\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "None\n",
      "Hi\n",
      "[]\n",
      "Number of tracks: 0\n",
      "\n",
      "0: 384x640 10 persons, 6 cars, 3 backpacks, 92.9ms\n",
      "Speed: 4.6ms preprocess, 92.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Number of detections: 14\n",
      "---------------\n",
      "[]\n",
      "---------------\n",
      "Matches A\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "None\n",
      "Hi\n",
      "[]\n",
      "Number of tracks: 0\n",
      "\n",
      "0: 384x640 11 persons, 6 cars, 2 backpacks, 92.7ms\n",
      "Speed: 5.5ms preprocess, 92.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Number of detections: 14\n",
      "---------------\n",
      "[]\n",
      "---------------\n",
      "Matches A\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "None\n",
      "Hi\n",
      "[]\n",
      "Number of tracks: 0\n",
      "\n",
      "0: 384x640 10 persons, 6 cars, 3 backpacks, 97.2ms\n",
      "Speed: 2.8ms preprocess, 97.2ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Number of detections: 14\n",
      "---------------\n",
      "[]\n",
      "---------------\n",
      "Matches A\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "None\n",
      "Hi\n",
      "[]\n",
      "Number of tracks: 0\n",
      "\n",
      "0: 384x640 10 persons, 7 cars, 3 backpacks, 98.8ms\n",
      "Speed: 7.6ms preprocess, 98.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Number of detections: 14\n",
      "---------------\n",
      "[]\n",
      "---------------\n",
      "Matches A\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "None\n",
      "Hi\n",
      "[]\n",
      "Number of tracks: 0\n",
      "\n",
      "0: 384x640 10 persons, 7 cars, 3 backpacks, 97.9ms\n",
      "Speed: 2.5ms preprocess, 97.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Number of detections: 15\n",
      "---------------\n",
      "[]\n",
      "---------------\n",
      "Matches A\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "None\n",
      "Hi\n",
      "[]\n",
      "Number of tracks: 0\n",
      "\n",
      "0: 384x640 10 persons, 6 cars, 2 backpacks, 111.9ms\n",
      "Speed: 3.2ms preprocess, 111.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Number of detections: 14\n",
      "---------------\n",
      "[]\n",
      "---------------\n",
      "Matches A\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "None\n",
      "Hi\n",
      "[]\n",
      "Number of tracks: 0\n",
      "\n",
      "0: 384x640 11 persons, 7 cars, 2 backpacks, 1 handbag, 99.1ms\n",
      "Speed: 2.5ms preprocess, 99.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Number of detections: 15\n",
      "---------------\n",
      "[]\n",
      "---------------\n",
      "Matches A\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "None\n",
      "Hi\n",
      "[]\n",
      "Number of tracks: 0\n",
      "\n",
      "0: 384x640 11 persons, 7 cars, 2 backpacks, 1 handbag, 93.6ms\n",
      "Speed: 7.0ms preprocess, 93.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Number of detections: 13\n",
      "---------------\n",
      "[]\n",
      "---------------\n",
      "Matches A\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "None\n",
      "Hi\n",
      "[]\n",
      "Number of tracks: 0\n",
      "\n",
      "0: 384x640 11 persons, 7 cars, 2 backpacks, 1 handbag, 93.7ms\n",
      "Speed: 1.5ms preprocess, 93.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Number of detections: 15\n",
      "---------------\n",
      "[]\n",
      "---------------\n",
      "Matches A\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "None\n",
      "Hi\n",
      "[]\n",
      "Number of tracks: 0\n",
      "\n",
      "0: 384x640 9 persons, 7 cars, 3 backpacks, 1 handbag, 89.9ms\n",
      "Speed: 2.5ms preprocess, 89.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Number of detections: 13\n",
      "---------------\n",
      "[]\n",
      "---------------\n",
      "Matches A\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "None\n",
      "Hi\n",
      "[]\n",
      "Number of tracks: 0\n",
      "\n",
      "0: 384x640 15 persons, 7 cars, 2 backpacks, 1 handbag, 96.7ms\n",
      "Speed: 10.7ms preprocess, 96.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Number of detections: 14\n",
      "---------------\n",
      "[]\n",
      "---------------\n",
      "Matches A\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "None\n",
      "Hi\n",
      "[]\n",
      "Number of tracks: 0\n",
      "\n",
      "0: 384x640 14 persons, 8 cars, 2 backpacks, 1 handbag, 86.9ms\n",
      "Speed: 4.0ms preprocess, 86.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Number of detections: 14\n",
      "---------------\n",
      "[]\n",
      "---------------\n",
      "Matches A\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "None\n",
      "Hi\n",
      "[]\n",
      "Number of tracks: 0\n",
      "\n",
      "0: 384x640 11 persons, 8 cars, 2 backpacks, 1 handbag, 97.0ms\n",
      "Speed: 7.4ms preprocess, 97.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Number of detections: 12\n",
      "---------------\n",
      "[]\n",
      "---------------\n",
      "Matches A\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "None\n",
      "Hi\n",
      "[]\n",
      "Number of tracks: 0\n",
      "\n",
      "0: 384x640 9 persons, 9 cars, 1 backpack, 1 handbag, 95.1ms\n",
      "Speed: 4.6ms preprocess, 95.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Number of detections: 12\n",
      "---------------\n",
      "[]\n",
      "---------------\n",
      "Matches A\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "None\n",
      "Hi\n",
      "[]\n",
      "Number of tracks: 0\n",
      "\n",
      "0: 384x640 8 persons, 5 cars, 1 backpack, 1 handbag, 98.2ms\n",
      "Speed: 6.7ms preprocess, 98.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Number of detections: 8\n",
      "---------------\n",
      "[]\n",
      "---------------\n",
      "Matches A\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "None\n",
      "Hi\n",
      "[]\n",
      "Number of tracks: 0\n",
      "\n",
      "0: 384x640 11 persons, 3 cars, 2 backpacks, 1 handbag, 98.4ms\n",
      "Speed: 3.0ms preprocess, 98.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Number of detections: 9\n",
      "---------------\n",
      "[]\n",
      "---------------\n",
      "Matches A\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "None\n",
      "Hi\n",
      "[]\n",
      "Number of tracks: 0\n",
      "\n",
      "0: 384x640 15 persons, 3 cars, 1 backpack, 1 handbag, 113.9ms\n",
      "Speed: 0.0ms preprocess, 113.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Number of detections: 8\n",
      "---------------\n",
      "[]\n",
      "---------------\n",
      "Matches A\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "None\n",
      "Hi\n",
      "[]\n",
      "Number of tracks: 0\n",
      "\n",
      "0: 384x640 14 persons, 3 cars, 1 backpack, 90.8ms\n",
      "Speed: 1.5ms preprocess, 90.8ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Number of detections: 12\n",
      "---------------\n",
      "[]\n",
      "---------------\n",
      "Matches A\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "None\n",
      "Hi\n",
      "[]\n",
      "Number of tracks: 0\n",
      "\n",
      "0: 384x640 13 persons, 5 cars, 1 backpack, 109.3ms\n",
      "Speed: 2.6ms preprocess, 109.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Number of detections: 11\n",
      "---------------\n",
      "[]\n",
      "---------------\n",
      "Matches A\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "None\n",
      "Hi\n",
      "[]\n",
      "Number of tracks: 0\n",
      "\n",
      "0: 384x640 11 persons, 5 cars, 2 backpacks, 92.7ms\n",
      "Speed: 2.0ms preprocess, 92.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Number of detections: 12\n",
      "---------------\n",
      "[]\n",
      "---------------\n",
      "Matches A\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "None\n",
      "Hi\n",
      "[]\n",
      "Number of tracks: 0\n",
      "\n",
      "0: 384x640 10 persons, 6 cars, 2 backpacks, 1 handbag, 97.0ms\n",
      "Speed: 3.0ms preprocess, 97.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Number of detections: 12\n",
      "---------------\n",
      "[]\n",
      "---------------\n",
      "Matches A\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "None\n",
      "Hi\n",
      "[]\n",
      "Number of tracks: 0\n",
      "\n",
      "0: 384x640 13 persons, 6 cars, 2 backpacks, 1 handbag, 97.0ms\n",
      "Speed: 1.7ms preprocess, 97.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Number of detections: 13\n",
      "---------------\n",
      "[]\n",
      "---------------\n",
      "Matches A\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "None\n",
      "Hi\n",
      "[]\n",
      "Number of tracks: 0\n",
      "\n",
      "0: 384x640 14 persons, 7 cars, 2 backpacks, 1 handbag, 93.6ms\n",
      "Speed: 3.4ms preprocess, 93.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Number of detections: 13\n",
      "---------------\n",
      "[]\n",
      "---------------\n",
      "Matches A\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "None\n",
      "Hi\n",
      "[]\n",
      "Number of tracks: 0\n",
      "\n",
      "0: 384x640 16 persons, 6 cars, 1 backpack, 1 handbag, 100.2ms\n",
      "Speed: 2.1ms preprocess, 100.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Number of detections: 13\n",
      "---------------\n",
      "[]\n",
      "---------------\n",
      "Matches A\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "None\n",
      "Hi\n",
      "[]\n",
      "Number of tracks: 0\n",
      "\n",
      "0: 384x640 14 persons, 6 cars, 4 backpacks, 1 handbag, 102.7ms\n",
      "Speed: 2.0ms preprocess, 102.7ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Number of detections: 12\n",
      "---------------\n",
      "[]\n",
      "---------------\n",
      "Matches A\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "None\n",
      "Hi\n",
      "[]\n",
      "Number of tracks: 0\n",
      "\n",
      "0: 384x640 11 persons, 6 cars, 4 backpacks, 1 handbag, 103.3ms\n",
      "Speed: 4.7ms preprocess, 103.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Number of detections: 12\n",
      "---------------\n",
      "[]\n",
      "---------------\n",
      "Matches A\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "None\n",
      "Hi\n",
      "[]\n",
      "Number of tracks: 0\n",
      "\n",
      "0: 384x640 15 persons, 5 cars, 3 backpacks, 1 handbag, 92.6ms\n",
      "Speed: 2.5ms preprocess, 92.6ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Number of detections: 14\n",
      "---------------\n",
      "[]\n",
      "---------------\n",
      "Matches A\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "None\n",
      "Hi\n",
      "[]\n",
      "Number of tracks: 0\n",
      "\n",
      "0: 384x640 13 persons, 6 cars, 2 backpacks, 1 handbag, 97.8ms\n",
      "Speed: 2.4ms preprocess, 97.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Number of detections: 12\n",
      "---------------\n",
      "[]\n",
      "---------------\n",
      "Matches A\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "None\n",
      "Hi\n",
      "[]\n",
      "Number of tracks: 0\n",
      "\n",
      "0: 384x640 15 persons, 6 cars, 2 backpacks, 1 handbag, 92.9ms\n",
      "Speed: 1.7ms preprocess, 92.9ms inference, 6.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Number of detections: 11\n",
      "---------------\n",
      "[]\n",
      "---------------\n",
      "Matches A\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "None\n",
      "Hi\n",
      "[]\n",
      "Number of tracks: 0\n",
      "\n",
      "0: 384x640 14 persons, 6 cars, 2 backpacks, 1 handbag, 107.4ms\n",
      "Speed: 2.4ms preprocess, 107.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Number of detections: 11\n",
      "---------------\n",
      "[]\n",
      "---------------\n",
      "Matches A\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "None\n",
      "Hi\n",
      "[]\n",
      "Number of tracks: 0\n",
      "[908, 686]\n",
      "\n",
      "0: 384x640 16 persons, 5 cars, 2 backpacks, 1 handbag, 93.7ms\n",
      "Speed: 1.2ms preprocess, 93.7ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Number of detections: 13\n",
      "---------------\n",
      "[]\n",
      "---------------\n",
      "Matches A\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "None\n",
      "Hi\n",
      "[]\n",
      "Number of tracks: 0\n",
      "[966, 334]\n",
      "\n",
      "0: 384x640 13 persons, 5 cars, 2 backpacks, 1 handbag, 96.0ms\n",
      "Speed: 2.0ms preprocess, 96.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Number of detections: 12\n",
      "---------------\n",
      "[]\n",
      "---------------\n",
      "Matches A\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "None\n",
      "Hi\n",
      "[]\n",
      "Number of tracks: 0\n",
      "[1077, 44]\n",
      "\n",
      "0: 384x640 14 persons, 4 cars, 2 backpacks, 97.7ms\n",
      "Speed: 1.9ms preprocess, 97.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Number of detections: 12\n",
      "---------------\n",
      "[]\n",
      "---------------\n",
      "Matches A\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "None\n",
      "Hi\n",
      "[]\n",
      "Number of tracks: 0\n",
      "[1077, 44]\n",
      "[1079, 43]\n",
      "\n",
      "0: 384x640 19 persons, 3 cars, 2 backpacks, 1 handbag, 103.9ms\n",
      "Speed: 2.0ms preprocess, 103.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Number of detections: 14\n",
      "---------------\n",
      "[]\n",
      "---------------\n",
      "Matches A\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "None\n",
      "Hi\n",
      "[]\n",
      "Number of tracks: 0\n",
      "[1182, 111]\n",
      "[1177, 119]\n",
      "\n",
      "0: 384x640 15 persons, 4 cars, 2 backpacks, 3 handbags, 91.5ms\n",
      "Speed: 2.6ms preprocess, 91.5ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Number of detections: 12\n",
      "---------------\n",
      "[]\n",
      "---------------\n",
      "Matches A\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "None\n",
      "Hi\n",
      "[]\n",
      "Number of tracks: 0\n",
      "[1137, 180]\n",
      "\n",
      "0: 384x640 14 persons, 4 cars, 2 backpacks, 2 handbags, 96.1ms\n",
      "Speed: 2.0ms preprocess, 96.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Number of detections: 16\n",
      "---------------\n",
      "[]\n",
      "---------------\n",
      "Matches A\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "None\n",
      "Hi\n",
      "[]\n",
      "Number of tracks: 0\n",
      "\n",
      "0: 384x640 13 persons, 4 cars, 2 backpacks, 2 handbags, 93.9ms\n",
      "Speed: 2.3ms preprocess, 93.9ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Number of detections: 12\n",
      "---------------\n",
      "[]\n",
      "---------------\n",
      "Matches A\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "None\n",
      "Hi\n",
      "[]\n",
      "Number of tracks: 0\n",
      "\n",
      "0: 384x640 16 persons, 4 cars, 4 backpacks, 3 handbags, 98.0ms\n",
      "Speed: 2.0ms preprocess, 98.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Number of detections: 13\n",
      "---------------\n",
      "[]\n",
      "---------------\n",
      "Matches A\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "None\n",
      "Hi\n",
      "[]\n",
      "Number of tracks: 0\n",
      "\n",
      "0: 384x640 17 persons, 4 cars, 3 backpacks, 2 handbags, 96.3ms\n",
      "Speed: 2.0ms preprocess, 96.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Number of detections: 17\n",
      "---------------\n",
      "[]\n",
      "---------------\n",
      "Matches A\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "None\n",
      "Hi\n",
      "[]\n",
      "Number of tracks: 0\n",
      "\n",
      "0: 384x640 13 persons, 4 cars, 2 backpacks, 4 handbags, 98.2ms\n",
      "Speed: 2.0ms preprocess, 98.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Number of detections: 14\n",
      "---------------\n",
      "[]\n",
      "---------------\n",
      "Matches A\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "None\n",
      "Hi\n",
      "[]\n",
      "Number of tracks: 0\n",
      "\n",
      "0: 384x640 14 persons, 3 cars, 4 backpacks, 2 handbags, 98.0ms\n",
      "Speed: 2.0ms preprocess, 98.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Number of detections: 14\n",
      "---------------\n",
      "[]\n",
      "---------------\n",
      "Matches A\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "None\n",
      "Hi\n",
      "[]\n",
      "Number of tracks: 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cv2.namedWindow('RGB')\n",
    "cv2.setMouseCallback('RGB', RGB)\n",
    "\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open video source.\")\n",
    "\n",
    "\n",
    "#cap_out = cv2.VideoWriter(video_out_path, cv2.VideoWriter_fourcc(*'MP4V'), cap.get(cv2.CAP_PROP_FPS),\n",
    "                         # (frame.shape[1], frame.shape[0]))\n",
    "\n",
    "model = YOLO(\"yolov8n.pt\")\n",
    "\n",
    "tracker = Tracker()\n",
    "\n",
    "\n",
    "\n",
    "colors = [(random.randint(0, 255), random.randint(0, 255), random.randint(0, 255)) for j in range(10)]\n",
    "count=0\n",
    "detection_threshold = 0.5\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    count += 1\n",
    "    if count % 2 != 0:\n",
    "        continue\n",
    "    \n",
    "    results = model(frame)\n",
    "\n",
    "    for result in results:\n",
    "        detections = []\n",
    "        for r in result.boxes.data.tolist():\n",
    "            x1, y1, x2, y2, score, class_id = r\n",
    "            x1 = int(x1)\n",
    "            x2 = int(x2)\n",
    "            y1 = int(y1)\n",
    "            y2 = int(y2)\n",
    "            class_id = int(class_id)\n",
    "            \n",
    "            if score > detection_threshold:\n",
    "                detections.append([x1, y1, x2, y2, score])\n",
    "\n",
    "        print(f\"Number of detections: {len(detections)}\")\n",
    "        tracker.update(frame, detections)\n",
    "        #print(tracker.dets)\n",
    "\n",
    "        print(f\"Number of tracks: {len(tracker.tracks)}\")\n",
    "        for track in tracker.tracks:\n",
    "            \n",
    "            bbox = track.bbox\n",
    "            x1, y1, x2, y2 = bbox\n",
    "            track_id = track.track_id\n",
    "            print(f\"Track ID: {track_id}, Bounding Box: ({x1}, {y1}) - ({x2}, {y2})\")\n",
    "\n",
    "            cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (colors[track_id % len(colors)]), 3)\n",
    "    \n",
    "    #cap_out.write(frame)\n",
    "    cv2.imshow('RGB',frame)\n",
    "    if cv2.waitKey(1)&0xFF==27:\n",
    "        \n",
    "        break\n",
    "    #ret, frame = cap.read()\n",
    "\n",
    "cap.release()\n",
    "#cap_out.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b76d56-023f-40e3-8086-c0f32d774a42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
